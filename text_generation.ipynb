{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1sy4xguzP9aFHeQWE3QZeBVZbgQgvgJYX","authorship_tag":"ABX9TyOcsgJ1tnYarmSr2+dg8M86"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xhyuOrmECjde","executionInfo":{"status":"ok","timestamp":1665388685446,"user_tz":420,"elapsed":1803,"user":{"displayName":"vikram parmar","userId":"15046216128454173516"}}},"outputs":[],"source":["from random import randint\n","from pickle import load\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np"]},{"cell_type":"code","source":["def load_doc(filename):\n","  # open the file as read only\n","  file = open(filename, 'r')\n","  # read all text\n","  text = file.read()\n","  # close the file\n","  file.close()\n","  return text\n","\n","# generate a sequence from a language model\n","def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n","  result = list()\n","  in_text = seed_text\n","  # generate a fixed number of words\n","  for _ in range(n_words):\n","    # encode the text as integer\n","    encoded = tokenizer.texts_to_sequences([in_text])[0]\n","    # truncate sequences to a fixed length\n","    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n","    # predict probabilities for each word\n","    predict_x = model.predict(encoded, verbose=0)\n","    yhat = np.argmax(predict_x, axis=1) \n","    # map predicted word index to word\n","    out_word = ''\n","    for word, index in tokenizer.word_index.items():\n","      if index == yhat:\n","        out_word = word\n","        break\n","    # append to input\n","    in_text += ' ' + out_word\n","    result.append(out_word)\n","  return ' '.join(result)"],"metadata":{"id":"gXqzHlp0Dfsp","executionInfo":{"status":"ok","timestamp":1665388689004,"user_tz":420,"elapsed":11,"user":{"displayName":"vikram parmar","userId":"15046216128454173516"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["in_filename = 'drive/MyDrive/ml/republic_seq.txt'\n","doc = load_doc(in_filename)\n","lines = doc.split('\\n')\n","seq_length = len(lines[0].split()) - 1\n","# load the model\n","model = load_model('drive/MyDrive/ml/lang_modeling_model.h5')\n","# load the tokenizer\n","tokenizer = load(open('drive/MyDrive/ml/tokenizer.pkl', 'rb'))\n","seed_text = lines[randint(0,len(lines))]\n","print(seed_text + '\\n')\n","# generate new text\n","generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n","print(generated)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUZOK0HuEBbb","executionInfo":{"status":"ok","timestamp":1665388702922,"user_tz":420,"elapsed":7239,"user":{"displayName":"vikram parmar","userId":"15046216128454173516"}},"outputId":"a5eb1ab8-9d7b-4ac4-95c9-c09440ec13b4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["therefore they all tend towards a common end certainly he replied and as they have nothing but their persons which they can call their own suits and complaints will have no existence among them they will be delivered from all those quarrels of which money or children or relations are the\n","\n","occasion of course they certainly have to excess nor these citizens which in all means he said and you may see that philosophers are two name involves the band of states for their who is few which is not studying their own things which is more with music which not\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CRI9g4jR5swC"},"execution_count":null,"outputs":[]}]}